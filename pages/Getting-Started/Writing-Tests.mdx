# Writing Tests

Unlike running tests, writing a spec file is usually straightforward and universal between runtimes.

When writing a spec file, you need to first return a table that returns functions. 
Those functions will be treated as a test case.

A Math library, and its spec file could look like this:
```lua
-- Math.luau
local Math = {}

function Math.add(a, b)
    return a + b
end 

function Math.subtract(a, b) 
    return a - b 
end

return Math

-- Math.spec.luau
local expect = CrescTest.expect 
return {
    should_add = function(skip)
        expect(Math.add(1, 1)).to.equal(2)
    end,
    should_subtract = function(skip) 
        expect(Math.subtract(1, 1)).to.equal(0)
    end
}
```

While this is usually enough for normal cases, CrescTest provides 
some useful lifecycle hooks that allow you to efficiently use
global state.

There is currently 4 lifecycle hooks, which are:
* `afterAll` - Runs after all test cases are ran.
* `afterEach` - Runs after each test case is ran.
* `beforeAll` - Runs before all test cases are ran.
* `beforeEach` - Runs before each test case runs.

Each of this is useful for some cases. For example the `xAll` functions 
are usually useful when you want to setup/clean some global state
before the entire test suite runs.

On the other hand, the `xEach` functions are usually useful 
when you want to specifically prepare/clean some state for each case.

import { Callout } from 'nextra/components'

<Callout>
    These functions are usually fired with (noOp, context), while afterEach is specifically fired with (noOp, context, isSkipped).
</Callout>
### Skipping Tests

Aside from lifecycle hooks, there is a `skip` function that gets injected into every test case.

This function skips the test it was called in, and if there is an `afterEach` hook present, then the `afterEach` hook will be fired with a boolean indicating 
if the previous test is skipped or not. This allows you to place some logic specifically for skipped tests. 